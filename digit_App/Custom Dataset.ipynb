{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40be6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import cv2 as cv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8ad24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('DigitData')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path('.//DigitData/')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a498d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('DigitData/0/img_1.jpg'),\n",
       " WindowsPath('DigitData/0/img_10007.jpg'),\n",
       " WindowsPath('DigitData/0/img_10010.jpg'),\n",
       " WindowsPath('DigitData/0/img_10017.jpg'),\n",
       " WindowsPath('DigitData/0/img_10032.jpg')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa95927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images are :  42000\n"
     ]
    }
   ],
   "source": [
    "print('total images are : ',len(list(data_dir.glob('*/*.jpg'))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4047455",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_images_dict = {\n",
    "    'zero': list(data_dir.glob('0/*'))[:500],\n",
    "    'one': list(data_dir.glob('1/*'))[:500],\n",
    "    'two': list(data_dir.glob('2/*'))[:500],\n",
    "    'three': list(data_dir.glob('3/*'))[:500],\n",
    "    'four': list(data_dir.glob('4/*'))[:500],\n",
    "    'five': list(data_dir.glob('5/*'))[:500],\n",
    "    'six': list(data_dir.glob('6/*'))[:500],\n",
    "    'seven': list(data_dir.glob('7/*'))[:500],\n",
    "    'eight': list(data_dir.glob('8/*'))[:500],\n",
    "    'nine': list(data_dir.glob('9/*'))[:500],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fd2924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "digit_label_dict = {\n",
    "    'zero': 0,\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three':3,\n",
    "    'four': 4,\n",
    "    'five': 5,\n",
    "    'six': 6,\n",
    "    'seven':7,\n",
    "    'eight':8,\n",
    "    'nine':9 ,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef3bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=[],[]\n",
    "for name , images in digit_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv.imread(str(image))\n",
    "        resize_img = cv.resize(img,(28,28))\n",
    "        X.append(resize_img)\n",
    "        y.append(digit_label_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c3401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y into numpy array\n",
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ae4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d28db120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[15])\n",
    "plt.title(y_train[15])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06757039",
   "metadata": {},
   "source": [
    "# convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9d9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8aba81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "\n",
    "model=Sequential();\n",
    "\n",
    "# Step 1 - Convolution\n",
    "model.add(Conv2D(32,(3,3),input_shape=(28,28,3),padding = 'Same',activation='relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Step 1 - Convolution\n",
    "model.add(Conv2D(16,(3,3),padding = 'Same',activation='relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Step 4 - Full connection\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer ='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a2bb27",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[10, 10, 10],\n",
       "         [ 0,  0,  0],\n",
       "         [ 4,  4,  4],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 5,  5,  5],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [15, 15, 15],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 2,  2,  2],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 2,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 4,  4,  4],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 1,  1,  1],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [14, 14, 14],\n",
       "         [18, 18, 18],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 7,  7,  7],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 6,  6,  6],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 2,  2,  2],\n",
       "         [ 3,  3,  3]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb734fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Scaled=X_train/255\n",
    "X_test_Scaled=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60c2b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002C5C1ACDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002C5C1ACDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "110/110 [==============================] - 23s 137ms/step - loss: 0.8069 - accuracy: 0.7400\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.2463 - accuracy: 0.9231\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1471 - accuracy: 0.9509\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 15s 141ms/step - loss: 0.0962 - accuracy: 0.9671\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.0576 - accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c5c1c51ec8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_Scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876c0260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002C5C9753D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002C5C9753D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "47/47 [==============================] - 3s 51ms/step - loss: 0.1570 - accuracy: 0.9527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15697789192199707, 0.9526666402816772]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_Scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b52dc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002C5CB5A1678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002C5CB5A1678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9963224e-01, 2.0262448e-12, 1.2008095e-06, ..., 2.5975664e-11,\n",
       "        1.1782436e-07, 6.5922562e-10],\n",
       "       [2.8394354e-06, 4.0386947e-09, 3.2965615e-06, ..., 9.5952356e-01,\n",
       "        1.4250195e-06, 4.0434275e-02],\n",
       "       [2.2208907e-08, 3.2758829e-09, 1.7385974e-09, ..., 8.5297543e-05,\n",
       "        1.6335223e-06, 9.9983585e-01],\n",
       "       ...,\n",
       "       [3.8345917e-08, 1.9835175e-08, 9.9999845e-01, ..., 8.5988543e-11,\n",
       "        1.1996741e-06, 6.4246720e-12],\n",
       "       [1.9360668e-08, 1.8704711e-07, 3.3759242e-09, ..., 2.2203842e-12,\n",
       "        6.7238048e-05, 2.8831748e-06],\n",
       "       [4.2119911e-08, 2.5437850e-05, 9.9997222e-01, ..., 2.1562799e-10,\n",
       "        9.6696454e-07, 6.4793535e-15]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_Scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab7e22c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score =tf.nn.softmax(predictions[98])\n",
    "np.argmax(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5068906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be26f036",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowKeyError",
     "evalue": "A type extension with name arrow.py_extension_type already defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowKeyError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\tensorflow\\__init__.py:473\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    472\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\engine\\functional.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_utils\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\engine\\training.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_layer \u001b[38;5;28;01mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\engine\\compile_utils.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses_mod\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_mod\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses_utils\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\metrics\\__init__.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SumOverBatchSizeMetricWrapper\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Individual metric classes\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MeanRelativeError\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accuracy\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryAccuracy\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\metrics\\metrics.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Union\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\activations.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mactivation_layers\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\layers\\__init__.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_spec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputSpec\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_preprocessing_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreprocessingLayer\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Image preprocessing layers.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CenterCrop\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base ProcessingLayer and a subclass that uses Combiners.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_utils\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\engine\\data_adapter.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   pd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\compat\\__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     is_numpy_dev,\n\u001b[0;32m     17\u001b[0m     np_version_under1p19,\n\u001b[0;32m     18\u001b[0m     np_version_under1p20,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     22\u001b[0m     pa_version_under2p0,\n\u001b[0;32m     23\u001b[0m     pa_version_under3p0,\n\u001b[0;32m     24\u001b[0m     pa_version_under4p0,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m PY39 \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m     28\u001b[0m PY310 \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\compat\\pyarrow.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     _pa_version \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m      9\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(_pa_version)\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pyarrow\\types.pxi:3357\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pyarrow\\types.pxi:3339\u001b[0m, in \u001b[0;36mpyarrow.lib._register_py_extension_type\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pyarrow\\error.pxi:119\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowKeyError\u001b[0m: A type extension with name arrow.py_extension_type already defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63344a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('test/Digit 1.0v.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a061c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a323d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ee0009",
   "metadata": {},
   "source": [
    "#  custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image=image.load_img('5.jpg',\n",
    "                         target_size = (28,28))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image, axis=0)\n",
    "result=model.predict(test_image)\n",
    "#      0 ,6 ,7 ,4\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f3d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number : 5\n"
     ]
    }
   ],
   "source": [
    "n=np.where(result==1.0)\n",
    "print('Detected number :',n[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d92343",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bedd3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model.save(\"model_saved.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405bb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_imodel(\"model_saved.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa96dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000271B08E9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000271B08E9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Detected number : 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image=image.load_img('5.jpg',\n",
    "                         target_size = (28,28))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image, axis=0)\n",
    "result=saved_model.predict(test_image)\n",
    "n=np.where(result==1.0)\n",
    "print('Detected number :',n[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e325a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
